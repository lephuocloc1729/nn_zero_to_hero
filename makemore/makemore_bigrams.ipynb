{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0z26LA-aGEX",
        "outputId": "8d18d4bb-289d-4350-cb75-220f1e0f9754"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/karpathy/makemore/master/names.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__L7HilbaIAu"
      },
      "outputs": [],
      "source": [
        "words = open('names.txt', 'r').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVFUzUrhai56",
        "outputId": "47dd40d0-8560-4213-8389-d5409e9b55de"
      },
      "outputs": [],
      "source": [
        "len(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW1CAF2Xako3",
        "outputId": "fb35f546-e756-4df2-d471-c825676725e6"
      },
      "outputs": [],
      "source": [
        "min([len(w) for w in words])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oNw6YWSsasnk",
        "outputId": "ddb78158-0361-4349-ce04-3c0779613d1d"
      },
      "outputs": [],
      "source": [
        "max(len(w) for w in words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APFHDuUgbqw6"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at6CaU4Lcp6h"
      },
      "outputs": [],
      "source": [
        "N = torch.zeros((27, 27), dtype = torch.int32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7XUAl6Gd4to"
      },
      "outputs": [],
      "source": [
        "chars = sorted(list(set(''.join(words))))\n",
        "stoi = {s:i + 1 for i, s in enumerate(chars)}\n",
        "stoi['.'] = 0\n",
        "itos = {i:s for s, i in stoi.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH_oCnfYauhr"
      },
      "outputs": [],
      "source": [
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    id1 = stoi[ch1]\n",
        "    id2 = stoi[ch2]\n",
        "    N[id1, id2] += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 924
        },
        "id": "rozryLIYfhq5",
        "outputId": "59be7a89-929d-4798-b1ad-108d237a1ff5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.figure(figsize= (16, 16))\n",
        "plt.imshow(N, cmap='Blues')\n",
        "for i in range(27):\n",
        "  for j in range(27) :\n",
        "    chstr = itos[i] + itos[j]\n",
        "    plt.text(j, i, chstr, ha=\"center\", va=\"bottom\", color='gray')\n",
        "    plt.text(j, i, N[i, j].item(), ha=\"center\", va=\"top\", color='gray')\n",
        "    plt.axis('off');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8pWl0pzvh80"
      },
      "outputs": [],
      "source": [
        "P = N / N.sum(axis = 1, keepdim = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O4ujKZ0JlUCo",
        "outputId": "0c639854-c95c-4a4f-bbdb-9c72ce0a8650"
      },
      "outputs": [],
      "source": [
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "  idx = 0\n",
        "  out = []\n",
        "  while True:\n",
        "    p = P[idx]\n",
        "    idx = torch.multinomial(p, num_samples = 1, replacement = True, generator = g).item()\n",
        "    out.append(itos[idx])\n",
        "    if idx == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRolPGrA3sFa"
      },
      "outputs": [],
      "source": [
        "xs = []\n",
        "ys = []\n",
        "for w in words[:1]:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    idx1 = stoi[ch1]\n",
        "    idx2 = stoi[ch2]\n",
        "    xs.append(idx1)\n",
        "    ys.append(idx2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K6fy6JULsM8M"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "x_enc = F.one_hot(xs, num_classes = 27).float()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "id": "1KI3h8QV4qls",
        "outputId": "a29b3509-06c2-458e-a2e0-ed1251a1bb9f"
      },
      "outputs": [],
      "source": [
        "plt.imshow(x_enc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oC6VL4Ee447R",
        "outputId": "765820fa-1ed1-4473-cb04-9a6cdf898da4"
      },
      "outputs": [],
      "source": [
        "W = torch.randn((27, 27), generator = g, requires_grad=True)\n",
        "x_enc @ W"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "Fh6Zfb2F9qNo",
        "outputId": "016eed3e-c7e1-4c1b-83db-9dac7f8657a3"
      },
      "outputs": [],
      "source": [
        "nlls = torch.zeros(5)\n",
        "for i in range(5):\n",
        "  x = xs[i].item()\n",
        "  y = ys[i].item()\n",
        "\n",
        "  p = probs[i, y]\n",
        "\n",
        "  logp = torch.log(p)\n",
        "\n",
        "  nll = -logp\n",
        "\n",
        "  nlls[i] = nll\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuzSd7039c8v"
      },
      "outputs": [],
      "source": [
        "# forward pass\n",
        "logits = x_enc @ W #log-counts\n",
        "counts = logits.exp()\n",
        "probs = counts / counts.sum(axis = 1, keepdims = True)\n",
        "loss = -probs[torch.arange(5), ys].log().mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "orNUF6TFWFfn"
      },
      "outputs": [],
      "source": [
        "loss.backward()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yyRzBqZIZiRZ"
      },
      "outputs": [],
      "source": [
        "W.data -= 0.1 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PuHPiSY6aY8N"
      },
      "outputs": [],
      "source": [
        "# create the dataset\n",
        "xs, ys = [], []\n",
        "for w in words:\n",
        "  chs = ['.'] + list(w) + ['.']\n",
        "  for ch1, ch2 in zip(chs, chs[1:]):\n",
        "    ix1 = stoi[ch1]\n",
        "    ix2 = stoi[ch2]\n",
        "    xs.append(ix1)\n",
        "    ys.append(ix2)\n",
        "xs = torch.tensor(xs)\n",
        "ys = torch.tensor(ys)\n",
        "num = xs.nelement()\n",
        "print('number of examples: ', num)\n",
        "\n",
        "# initialize the 'network'\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "W = torch.randn((27, 27), generator=g, requires_grad=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# gradient descent\n",
        "for k in range(1):\n",
        "  \n",
        "  # forward pass\n",
        "  xenc = F.one_hot(xs, num_classes=27).float() # input to the network: one-hot encoding\n",
        "  logits = xenc @ W # predict log-counts\n",
        "  counts = logits.exp() # counts, equivalent to N\n",
        "  probs = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "  loss = -probs[torch.arange(num), ys].log().mean() + 0.01*(W**2).mean()\n",
        "  print(loss.item())\n",
        "  \n",
        "  # backward pass\n",
        "  W.grad = None # set to zero the gradient\n",
        "  loss.backward()\n",
        "  \n",
        "  # update\n",
        "  W.data += -50 * W.grad"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# finally, sample from the 'neural net' model\n",
        "g = torch.Generator().manual_seed(2147483647)\n",
        "\n",
        "for i in range(5):\n",
        "  \n",
        "  out = []\n",
        "  ix = 0\n",
        "  while True:\n",
        "    \n",
        "    # ----------\n",
        "    # BEFORE:\n",
        "    #p = P[ix]\n",
        "    # ----------\n",
        "    # NOW:\n",
        "    xenc = F.one_hot(torch.tensor([ix]), num_classes=27).float()\n",
        "    logits = xenc @ W # predict log-counts\n",
        "    counts = logits.exp() # counts, equivalent to N\n",
        "    p = counts / counts.sum(1, keepdims=True) # probabilities for next character\n",
        "    # ----------\n",
        "    \n",
        "    ix = torch.multinomial(p, num_samples=1, replacement=True, generator=g).item()\n",
        "    out.append(itos[ix])\n",
        "    if ix == 0:\n",
        "      break\n",
        "  print(''.join(out))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
